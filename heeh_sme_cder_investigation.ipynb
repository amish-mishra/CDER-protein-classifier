{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate which CDER feature(s) are improving model performance alongside SME features\n",
    "Author: Amish Mishra  \n",
    "Date: June 25, 2025  \n",
    "Use `cder2` kernel  \n",
    "This notebook loads in the feature dataframes from the `/features_dataframes` directory for training SME+CDER models for the HEEH topology. This notebook investigates using a forward-selection method of which CDER feature is contributing to model performance improvement over the baseline SME features model.\n",
    "\n",
    "I copied the `6sme-cder-ml.ipynb` notebook as a template for this one.\n",
    "\n",
    "## Cautionary Notes\n",
    "Given a protein design topology (say HEEH):\n",
    "\n",
    "For the bubble-chart for finding correlations and ranking by feature importance, the attributes of that chart were computed as follows\n",
    "- the feature importance of the CDER features was found by training a model with no train/test split (just one big training set) on the pdbs\n",
    "- the feature importance of the SME features was found the same way\n",
    "- the correlations between the CDER and SME were found by analyzing the no train/test split dataset with both CDER and SME features\n",
    "\n",
    "For the performance analysis\n",
    "- a train/test split was performed **at the beginning** when selecting pdb files\n",
    "- a model was trained on the training data by first using the pdbs to generate persistence diagrams (PDs), learn CDER coordinates, and then use the coordinates to vectorize the train PDs.\n",
    "\n",
    "**Bottom line**: This means that when asking the question \"why did we see a ~3% increase in performance of the models using SME+CDER over just using SME?\" we have to be careful. We cannot directly assess what happens when we only add one CDER feature to the pipeline.\n",
    "\n",
    "Instead, what I do in this notebook is take the no train/test split dataset with the SME+CDER features and train a 10-fold CV random forest model with just one CDER feature at a time and assess the average APS across the folds. This means that technically information from the test sets of each fold have helped in finding the CDER features for the training set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import pickle\n",
    "import pandas\n",
    "# import multidim\n",
    "import numpy as np\n",
    "# from sklearn import metrics\n",
    "# from multidim.models import CDER\n",
    "# from multidim.covertree import CoverTree\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as sps\n",
    "from sklearn import model_selection\n",
    "# from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model on just the CDER features for the no train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_0_green[-1.1] only included with SME features\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "-- RF best params --\n",
      "{'max_depth': 80, 'max_features': 0.21395444988101142, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
      "-- RF best APS --\n",
      "0.8781952867927749\n",
      "H_0_red[-1.24] only included with SME features\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "-- RF best params --\n",
      "{'max_depth': 60, 'max_features': 0.046387077770056906, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
      "-- RF best APS --\n",
      "0.8579052365691299\n",
      "H_0_green[-0.94] only included with SME features\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "-- RF best params --\n",
      "{'max_depth': 40, 'max_features': 0.22332512638773205, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "-- RF best APS --\n",
      "0.8665205640234663\n",
      "H_0_green[-1.21] only included with SME features\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "-- RF best params --\n",
      "{'max_depth': 80, 'max_features': 0.4161218966392144, 'min_samples_leaf': 10, 'min_samples_split': 30}\n",
      "-- RF best APS --\n",
      "0.8614580416443278\n",
      "H_1_green[0.69 0.24] only included with SME features\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "-- RF best params --\n",
      "{'max_depth': 20, 'max_features': 0.06777557757882302, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
      "-- RF best APS --\n",
      "0.8630628933310647\n",
      "H_1_red[-0.41  2.95] only included with SME features\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "-- RF best params --\n",
      "{'max_depth': None, 'max_features': 0.39606545616515054, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
      "-- RF best APS --\n",
      "0.8582393363300342\n",
      "H_1_red[27.75  0.04] only included with SME features\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "-- RF best params --\n",
      "{'max_depth': 80, 'max_features': 0.5105127413267915, 'min_samples_leaf': 8, 'min_samples_split': 5}\n",
      "-- RF best APS --\n",
      "0.8549654827040134\n",
      "H_1_green[11.89  0.13] only included with SME features\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "-- RF best params --\n",
      "{'max_depth': 30, 'max_features': 0.09370252411234137, 'min_samples_leaf': 8, 'min_samples_split': 5}\n",
      "-- RF best APS --\n",
      "0.8557133813683736\n",
      "H_2_green[1.53 0.08] only included with SME features\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "-- RF best params --\n",
      "{'max_depth': 100, 'max_features': 0.980108865755676, 'min_samples_leaf': 10, 'min_samples_split': 30}\n",
      "-- RF best APS --\n",
      "0.856027647692809\n",
      "H_2_red[11.09  0.11] only included with SME features\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "-- RF best params --\n",
      "{'max_depth': 10, 'max_features': 0.3432717156683053, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "-- RF best APS --\n",
      "0.8611239450205641\n"
     ]
    }
   ],
   "source": [
    "topology = 'HEEH'\n",
    "\n",
    "# Save the features dataframes\n",
    "X_data_file = pandas.read_csv(f'features_dataframes/sme_cder_train_X_{topology}_no_train_test_split.csv')\n",
    "y_train = pandas.read_csv(f'features_dataframes/sme_cder_train_ylabels_{topology}_no_train_test_split.csv')\n",
    "\n",
    "perf_dict = {}\n",
    "for col in X_data_file.columns[:10]:\n",
    "    print(f'{col} only included with SME features')\n",
    "    X_train = X_data_file.loc[:, [col] + list(X_data_file.columns[-109:])]\n",
    "\n",
    "\n",
    "    # =================== RF =========================\n",
    "    # perform randomized search over rf hyperparameters\n",
    "\n",
    "    # relabel classes from CDER colors to binary labels\n",
    "    bin_labels_train = np.array([1 if label == 'green' else 0 for label in y_train['true_label']])\n",
    "\n",
    "    # Changed original n_estimators 1000 to 100, and n_iter 100 to 10\n",
    "    rf_clf = RandomForestClassifier(n_estimators=500, class_weight='balanced')\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "    max_depth.append(None)\n",
    "    rf_param_grid = {'max_features': sps.uniform, \n",
    "                        'max_depth': max_depth,\n",
    "                        'min_samples_split': [2, 5, 10, 20, 30],\n",
    "                        'min_samples_leaf': [1, 2, 4, 6, 8, 10]}\n",
    "\n",
    "    rf_clf_gs = model_selection.RandomizedSearchCV(rf_clf, \n",
    "                                                    rf_param_grid,\n",
    "                                                    scoring='average_precision', \n",
    "                                                    n_iter = 10,\n",
    "                                                    cv=10, \n",
    "                                                    n_jobs=-1,\n",
    "                                                    verbose=1)\n",
    "\n",
    "    rf_clf_gs.fit(X_train, bin_labels_train)\n",
    "\n",
    "    print('-- RF best params --')\n",
    "    print(rf_clf_gs.best_params_)\n",
    "\n",
    "    print('-- RF best APS --')\n",
    "    print(rf_clf_gs.best_score_)\n",
    "\n",
    "    # Save the performance metrics\n",
    "    perf_dict[col] = {'rf_best_params': rf_clf_gs.best_params_,\n",
    "                      'rf_best_aps': rf_clf_gs.best_score_}\n",
    "    # classifier_path = f'classifiers/cder_{topology}_rf_clf_gs_no_train_test_split.pickle'\n",
    "    # with open(classifier_path, 'wb') as f:\n",
    "    #     pickle.dump(rf_clf_gs, f, protocol=pickle.HIGHEST_PROTOCOL)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best APS: 0.8781952867927749 for H_0_green[-1.1] feature set\n"
     ]
    }
   ],
   "source": [
    "# Show which key in the dictionary has the best APS\n",
    "best_aps = max(perf_dict.items(), key=lambda x: x[1]['rf_best_aps'])\n",
    "print(f'Best APS: {best_aps[1][\"rf_best_aps\"]} for {best_aps[0]} feature set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline SME-only model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "topology = 'HEEH'\n",
    "\n",
    "# Remove only the 'H_' columns from the dataframe\n",
    "X_train = X_data_file.drop(X_data_file.filter(regex=r'^H_').columns, axis=1)\n",
    "\n",
    "# =================== RF =========================\n",
    "# perform randomized search over rf hyperparameters\n",
    "\n",
    "# relabel classes from CDER colors to binary labels\n",
    "bin_labels_train = np.array([1 if label == 'green' else 0 for label in y_train['true_label']])\n",
    "\n",
    "# Changed original n_estimators 1000 to 100, and n_iter 100 to 10\n",
    "rf_clf = RandomForestClassifier(n_estimators=500, class_weight='balanced')\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "rf_param_grid = {'max_features': sps.uniform, \n",
    "                    'max_depth': max_depth,\n",
    "                    'min_samples_split': [2, 5, 10, 20, 30],\n",
    "                    'min_samples_leaf': [1, 2, 4, 6, 8, 10]}\n",
    "\n",
    "rf_clf_gs = model_selection.RandomizedSearchCV(rf_clf, \n",
    "                                                rf_param_grid,\n",
    "                                                scoring='average_precision', \n",
    "                                                n_iter = 10,\n",
    "                                                cv=10, \n",
    "                                                n_jobs=-1,\n",
    "                                                verbose=1)\n",
    "\n",
    "rf_clf_gs.fit(X_train, bin_labels_train)\n",
    "\n",
    "print('-- RF best params --')\n",
    "print(rf_clf_gs.best_params_)\n",
    "\n",
    "print('-- RF best APS --')\n",
    "print(rf_clf_gs.best_score_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SME+CDER features model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topology = 'HEEH'\n",
    "\n",
    "X_train = X_data_file\n",
    "\n",
    "# =================== RF =========================\n",
    "# perform randomized search over rf hyperparameters\n",
    "\n",
    "# relabel classes from CDER colors to binary labels\n",
    "bin_labels_train = np.array([1 if label == 'green' else 0 for label in y_train['true_label']])\n",
    "\n",
    "# Changed original n_estimators 1000 to 100, and n_iter 100 to 10\n",
    "rf_clf = RandomForestClassifier(n_estimators=500, class_weight='balanced')\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "rf_param_grid = {'max_features': sps.uniform, \n",
    "                    'max_depth': max_depth,\n",
    "                    'min_samples_split': [2, 5, 10, 20, 30],\n",
    "                    'min_samples_leaf': [1, 2, 4, 6, 8, 10]}\n",
    "\n",
    "rf_clf_gs = model_selection.RandomizedSearchCV(rf_clf, \n",
    "                                                rf_param_grid,\n",
    "                                                scoring='average_precision', \n",
    "                                                n_iter = 10,\n",
    "                                                cv=10, \n",
    "                                                n_jobs=-1,\n",
    "                                                verbose=1)\n",
    "\n",
    "rf_clf_gs.fit(X_train, bin_labels_train)\n",
    "\n",
    "print('-- RF best params --')\n",
    "print(rf_clf_gs.best_params_)\n",
    "\n",
    "print('-- RF best APS --')\n",
    "print(rf_clf_gs.best_score_) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cder2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
